{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx1rog901EUD3zc+YLAaqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepak-Mewada/NeuralDecoder/blob/main/BrainDecoder/Basics/BenchMarking_eager_and_lazy_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjso4PsXY_af",
        "outputId": "1e481265-f6a5-41bb-a7e0-f62d37bf450d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwAkmtN8aela",
        "outputId": "899edc50-1e9b-4f03-985d-2e6ced8a0086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install braindecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTp22jIa27A",
        "outputId": "8f16333b-917a-42c9-e53d-1261c25c4ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: braindecode in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.9.0)\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (from braindecode) (0.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from braindecode) (2.1.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from braindecode) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.3.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.8.0)\n",
            "Requirement already satisfied: docstring-inheritance in /usr/local/lib/python3.10/dist-packages (from braindecode) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (0.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->braindecode) (2023.3.post1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode) (1.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (2.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode) (4.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->braindecode) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->braindecode) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->braindecode) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from braindecode.datasets import TUHAbnormal\n",
        "from braindecode.preprocessing import create_fixed_length_windows\n",
        "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
        "\n",
        "\n",
        "mne.set_log_level('WARNING')"
      ],
      "metadata": {
        "id": "Pwuyh9FpaaJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_JOBS = 8\n",
        "torch.backends.cudnn.benchmark = True  # Enables automatic algorithm optimizations\n",
        "torch.set_num_threads(N_JOBS)"
      ],
      "metadata": {
        "id": "mn4AtABiZH3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TUH_PATH = ('/storage/store/data/tuh_eeg/www.isip.piconepress.com/projects/'\n",
        "            'tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0')"
      ],
      "metadata": {
        "id": "5j2te-XRrb1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_example_data(preload, window_len_s, n_recordings=10, add_physician_reports=False, n_jobs=1):\n",
        "\n",
        "    recording_ids = list(range(n_recordings))\n",
        "\n",
        "    ds = TUHAbnormal(\n",
        "        TUH_PATH, recording_ids=recording_ids,\n",
        "        target_name='pathological',\n",
        "        preload=preload)\n",
        "\n",
        "    fs = ds.datasets[0].raw.info['sfreq']\n",
        "    window_len_samples = int(fs * window_len_s)\n",
        "    window_stride_samples = int(fs * 4)\n",
        "    windows_ds = create_fixed_length_windows(\n",
        "        ds, start_offset_samples=0, stop_offset_samples=None,\n",
        "        window_size_samples=window_len_samples,\n",
        "        window_stride_samples=window_stride_samples, drop_last_window=True,\n",
        "        preload=preload)\n",
        "\n",
        "\n",
        "    for ds in windows_ds.datasets:\n",
        "        ds.windows.drop_bad()\n",
        "        assert ds.windows.preload == preload\n",
        "\n",
        "    return windows_ds\n",
        "\n",
        "\n",
        "def create_example_model(n_channels, n_classes, window_len_samples,\n",
        "                         kind='shallow', cuda=False):\n",
        "\n",
        "    if kind == 'shallow':\n",
        "        model = ShallowFBCSPNet(\n",
        "            n_channels, n_classes, input_window_samples=window_len_samples,\n",
        "            n_filters_time=40, filter_time_length=25, n_filters_spat=40,\n",
        "            pool_time_length=75, pool_time_stride=15, final_conv_length='auto',\n",
        "            split_first_layer=True, batch_norm=True, batch_norm_alpha=0.1,\n",
        "            drop_prob=0.5)\n",
        "    elif kind == 'deep':\n",
        "        model = Deep4Net(\n",
        "            n_channels, n_classes, input_window_samples=window_len_samples,\n",
        "            final_conv_length='auto', n_filters_time=25, n_filters_spat=25,\n",
        "            filter_time_length=10, pool_time_length=3, pool_time_stride=3,\n",
        "            n_filters_2=50, filter_length_2=10, n_filters_3=100,\n",
        "            filter_length_3=10, n_filters_4=200, filter_length_4=10,\n",
        "            first_pool_mode=\"max\", later_pool_mode=\"max\", drop_prob=0.5,\n",
        "            double_time_convs=False, split_first_layer=True, batch_norm=True,\n",
        "            batch_norm_alpha=0.1, stride_before_pool=False)\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    loss = nn.NLLLoss()\n",
        "\n",
        "    return model, loss, optimizer\n",
        "\n",
        "\n",
        "def run_training(model, dataloader, loss, optimizer, n_epochs=1, cuda=False):\n",
        "    for i in range(n_epochs):\n",
        "        loss_vals = list()\n",
        "        for X, y, _ in dataloader:\n",
        "            model.train()\n",
        "            model.zero_grad()\n",
        "\n",
        "            y = y.long()\n",
        "            if cuda:\n",
        "                X, y = X.cuda(), y.cuda()\n",
        "\n",
        "            loss_val = loss(model(X), y)\n",
        "            loss_vals.append(loss_val.item())\n",
        "\n",
        "            loss_val.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {i + 1} - mean training loss: {np.mean(loss_vals)}')\n",
        "\n",
        "    return model\n",
        "PRELOAD = [True, False]\n",
        "N_RECORDINGS = [10]\n",
        "WINDOW_LEN_S = [2, 4, 15]\n",
        "N_EPOCHS = [2]\n",
        "BATCH_SIZE = [64, 256]\n",
        "MODEL = ['shallow', 'deep']\n",
        "\n",
        "NUM_WORKERS = [8, 0]\n",
        "PIN_MEMORY = [False]\n",
        "CUDA = [True, False] if torch.cuda.is_available() else [False]\n",
        "\n",
        "N_REPETITIONS = 3"
      ],
      "metadata": {
        "id": "qK-CrbUIZIG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = list()\n",
        "for (i, preload, n_recordings, win_len_s, n_epochs, batch_size, model_kind,\n",
        "        num_workers, pin_memory, cuda) in product(\n",
        "            range(N_REPETITIONS), PRELOAD, N_RECORDINGS, WINDOW_LEN_S, N_EPOCHS,\n",
        "            BATCH_SIZE, MODEL, NUM_WORKERS, PIN_MEMORY, CUDA):\n",
        "\n",
        "    results = {\n",
        "        'repetition': i,\n",
        "        'preload': preload,\n",
        "        'n_recordings': n_recordings,\n",
        "        'win_len_s': win_len_s,\n",
        "        'n_epochs': n_epochs,\n",
        "        'batch_size': batch_size,\n",
        "        'model_kind': model_kind,\n",
        "        'num_workers': num_workers,\n",
        "        'pin_memory': pin_memory,\n",
        "        'cuda': cuda\n",
        "    }\n",
        "    print(f'\\nRepetition {i + 1}/{N_REPETITIONS}:\\n{results}')\n",
        "\n",
        "    # Load the dataset\n",
        "    data_loading_start = time.time()\n",
        "    dataset = load_example_data(preload, win_len_s, n_recordings=n_recordings)\n",
        "    data_loading_end = time.time()\n",
        "\n",
        "    # Create the data loader\n",
        "    training_setup_start = time.time()\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, pin_memory=pin_memory,\n",
        "        num_workers=num_workers, worker_init_fn=None)\n",
        "\n",
        "    # Instantiate model and optimizer\n",
        "    n_channels = len(dataset.datasets[0].windows.ch_names)\n",
        "    n_times = len(dataset.datasets[0].windows.times)\n",
        "    n_classes = 2\n",
        "    model, loss, optimizer = create_example_model(\n",
        "        n_channels, n_classes, n_times, kind=model_kind, cuda=cuda)\n",
        "    training_setup_end = time.time()\n",
        "\n",
        "    # Start training loop\n",
        "    model_training_start = time.time()\n",
        "    trained_model = run_training(\n",
        "        model, dataloader, loss, optimizer, n_epochs=n_epochs, cuda=cuda)\n",
        "    model_training_end = time.time()\n",
        "\n",
        "    del dataset, model, loss, optimizer, trained_model\n",
        "\n",
        "    # Record timing results\n",
        "    results['data_preparation'] = data_loading_end - data_loading_start\n",
        "    results['training_setup'] = training_setup_end - training_setup_start\n",
        "    results['model_training'] = model_training_end - model_training_start\n",
        "    all_results.append(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "tIlYlqXHZIWJ",
        "outputId": "5c7957a2-dba0-44ab-a2a4-fcf0652e744e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Repetition 1/3:\n",
            "{'repetition': 0, 'preload': True, 'n_recordings': 10, 'win_len_s': 2, 'n_epochs': 2, 'batch_size': 64, 'model_kind': 'shallow', 'num_workers': 8, 'pin_memory': False, 'cuda': False}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'year'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-05e6b7de890d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdata_loading_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_example_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_len_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_recordings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_recordings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mdata_loading_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-26b5503a7c5e>\u001b[0m in \u001b[0;36mload_example_data\u001b[0;34m(preload, window_len_s, n_recordings, add_physician_reports, n_jobs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrecording_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_recordings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     ds = TUHAbnormal(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mTUH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecording_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecording_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtarget_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pathological'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/braindecode/datasets/tuh.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, recording_ids, target_name, preload, add_physician_reports, n_jobs)\u001b[0m\n\u001b[1;32m    299\u001b[0m                  preload=False, add_physician_reports=False, n_jobs=1):\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             warnings.filterwarnings(\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \"ignore\", message=\".*not in description. '__getitem__'\")\n\u001b[1;32m    303\u001b[0m             super().__init__(path=path, recording_ids=recording_ids,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/braindecode/datasets/tuh.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, recording_ids, target_name, preload, add_physician_reports, n_jobs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# sort the descriptions chronologicaly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sort_chronologically\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# limit to specified recording ids before doing slow stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecording_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/braindecode/datasets/tuh.py\u001b[0m in \u001b[0;36m_sort_chronologically\u001b[0;34m(descriptions)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdescriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sort_chronologically\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     descriptions.sort_values(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6894\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6894\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             )\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'year'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qEFHZH-ZIio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQvwH7FBZIvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gySF-TryZI8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}